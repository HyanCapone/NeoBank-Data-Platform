# üí∏ FinOps & Escalabilidade: Plataforma de Dados Azure NeoBank

Como Engenheiro de Dados, construir a plataforma √© apenas metade da batalha. Projet√°-la para ser eficiente em custos e entender quando e como ela deve escalar √© o que define uma arquitetura madura.

Abaixo est√° o plano de estimativa de custos e escalabilidade para a Plataforma de Dados NeoBank, calculado para a regi√£o **East US 2** (com base nos limites oficiais de pre√ßos do Azure).

---

## Cen√°rio A: Prova de Conceito (POC) / Desenvolvimento
Em um ambiente de aprendizado ou POC, os custos s√£o mantidos estritamente no m√≠nimo usando as camadas mais b√°sicas vi√°veis e aproveitando o auto-encerramento (auto-termination).

| Servi√ßo Azure | Configura√ß√£o (POC) | Uso Ativo | Custo Estimado (Mensal) |
| :--- | :--- | :--- | :--- |
| **Data Lake Storage Gen2** | Hot Tier, LRS (~1 GB de dados) | 24/7 (Apenas armazenamento) | **~$0.02** |
| **Azure Databricks** | Standard Tier (All-Purpose Compute)<br>Single Node (`Standard_DS3_v2`)<br>Auto-encerramento em 30 min | 10 Horas / M√™s | **~$5.50** <br>*(~$0.40/DBU + VM)* |
| **Synapse Analytics** | Dedicated SQL Pool (DW100c)<br>Pausado quando n√£o utilizado | 2 Horas / M√™s | **~$3.02** <br>*(~$1.51/Hora)* |
| **Custo Total Estimado (POC)** | **Arquitetura M√≠nima Vi√°vel** | **~12 Horas de Atividade** | **~$8.54 / M√™s** |

### Destaques FinOps para a POC:
- **Nunca deixe o Synapse Dedicated Pool rodando.** Pools SQL Dedicados cobram por hora, quer voc√™ execute consultas ou n√£o. SEMPRE PAUSE o pool ap√≥s suas opera√ß√µes de `COPY INTO`.
- **Auto-encerramento do Databricks:** Configurar clusters para desligar ap√≥s 30 minutos de inatividade economiza centenas de d√≥lares em uma equipe.

---

## Cen√°rio B: MVP do Mundo Real em Produ√ß√£o & Escalabilidade
Uma POC de $9 √© √≥tima, mas quantos dados essa exata arquitetura consegue lidar em um cen√°rio do mundo real antes de "quebrar"?

### Limites da Arquitetura Atual (O Setup "B√°sico" de Produ√ß√£o)
Mesmo na configura√ß√£o mais baixa (Single Node Databricks + DW100c Synapse), esta arquitetura √© incrivelmente poderosa:
1. **Azure Databricks (`Standard_DS3_v2`):** Pode confortavelmente ingerir, transformar (SCD-2) e carregar entre **20 GB a 50 GB de novos dados di√°rios** durante uma janela de lote (batch) noturna.
2. **Azure Synapse (DW100c):** Pode armazenar **~1 TB de dados hist√≥ricos comprimidos de Data Warehousing** (usando √çndices Clustered Columnstore) e servir dashboards do Power BI para dezenas de usu√°rios simult√¢neos com lat√™ncia de sub-segundos.

### Quando Escalar (Os Gatilhos)
Quando o neg√≥cio cresce al√©m do MVP, voc√™ n√£o reescreve o c√≥digo. Voc√™ simplesmente escala a computa√ß√£o nativamente no Azure.

#### 1. Quando escalar o Azure Databricks (Compute Up)
* **O Gatilho:** Seu pipeline ETL noturno (Bronze ‚ûî Silver ‚ûî Gold) come√ßa a exceder a janela de SLA acordada (ex: um processo que levava 15 minutos agora leva 2 horas devido ao volume de dados).
* **A A√ß√£o:** Mude de um cluster *Single Node* para um *Multi-Node Standard Cluster* e habilite o **Autoscaling** (ex: Min 2 Workers, Max 8 Workers). A natureza distribu√≠da do Spark particionar√° automaticamente a carga de trabalho pelos novos n√≥s.

#### 2. Quando escalar o Azure Synapse Analytics (DWU Up)
* **O Gatilho (Concorr√™ncia):** Voc√™ tem centenas de Analistas de BI ou ferramentas de relat√≥rios automatizados disparando consultas complexas simultaneamente, fazendo com que as consultas entrem em fila de espera.
* **O Gatilho (Lentid√£o Ad-Hoc):** Consultas anal√≠ticas complexas sobre dados hist√≥ricos massivos n√£o particionados come√ßam a ficar lentas. Em um DW100c, voc√™ tem apenas **1 Compute Node** gerenciando todas as 60 distribui√ß√µes internas do Synapse.
* **A A√ß√£o:** Mova o controle deslizante para **DW400c** ou **DW500c**. No DW400c, o Azure ativa 4 Compute Nodes dedicados nos bastidores, o que significa que cada n√≥ √© respons√°vel por consultar apenas 15 distribui√ß√µes em paralelo, reduzindo drasticamente o tempo de consulta em bilh√µes de linhas.
